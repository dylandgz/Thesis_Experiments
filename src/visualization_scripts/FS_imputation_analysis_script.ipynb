{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline and Feature Selection for Imputer Value vs Missing Rates Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all data from baseline and feature selection pipeline for imputation evaluation only. RMSE only. Baseline is no feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\"Chi_square\": \"/home/abhishek/Desktop/Thesis/Thesis/Feature_Selection/RFE\",\n",
    "#                                  \"correlation_coefficient\": \"/home/abhishek/Desktop/Thesis/Thesis/Feature_Selection/RFECV\",\n",
    "#                                  \"GA\": \"/home/abhishek/Desktop/Thesis/Thesis/Feature_Selection/SelectKBest\",\n",
    "#                                 \"IG\": \"/home/abhishek/Desktop/Thesis/Thesis/Feature_Selection/SelectFromModel\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# # Initialize the dictionary to store DataFrames\n",
    "# dataframes = {}\n",
    "\n",
    "# Function to load data from the experiment directory\n",
    "def load_experiment_data(dataframes,directory,experiment_type_name):\n",
    "    # Traverse through all files and directories in the given directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check for baseline data in the baseline folder\n",
    "            if \"baseline\" in root and experiment_type_name in file and file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Load the baseline data into the 'baseline' DataFrame\n",
    "                if 'baseline' not in dataframes:\n",
    "                    dataframes['baseline'] = pd.read_csv(file_path)\n",
    "                else:\n",
    "                    # Append new data to the existing baseline DataFrame\n",
    "                    data = pd.read_csv(file_path)\n",
    "                    dataframes['baseline'] = pd.concat([dataframes['baseline'], data], ignore_index=True)\n",
    "\n",
    "            # Check for data in fs_pipeline folder\n",
    "            elif \"fs_pipeline\" in root and experiment_type_name in file and file.endswith('.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                prefix = file.split(experiment_type_name)[0].rstrip('_')  # Remove trailing '_'\n",
    "                \n",
    "                # Load the data into the appropriate DataFrame named by the prefix\n",
    "                if prefix not in dataframes:\n",
    "                    dataframes[prefix] = pd.read_csv(file_path)\n",
    "                else:\n",
    "                    # Append new data to the existing DataFrame\n",
    "                    data = pd.read_csv(file_path)\n",
    "                    dataframes[prefix] = pd.concat([dataframes[prefix], data], ignore_index=True)\n",
    "    return dataframes\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# code takes directory that contains all the data.\n",
    "# Two directories, Baseline and  multiple directories for different types of feature selection\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a new dictionary to store DataFrames without NA values\n",
    "# dataframes_no_na = {}\n",
    "def drop_na(dataframes, dataframes_no_na):\n",
    "    # Iterate through each DataFrame in the original dictionary\n",
    "    for key, df in dataframes.items():\n",
    "        df_no_na = df.rename(columns={df.columns[0]: \"measure_and_missing_rates\"}, inplace=True)\n",
    "        # Drop all NA values from the DataFrame\n",
    "        df_no_na = df.dropna()\n",
    "        \n",
    "        # Save the cleaned DataFrame into the new dictionary with \"_no_na\" appended to the key\n",
    "        dataframes_no_na[f\"{key}_no_na\"] = df_no_na\n",
    "    return dataframes_no_na\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a new dictionary to store DataFrames with specific rows removed\n",
    "# dataframes_clean_data = {}\n",
    "\n",
    "######\n",
    "######\n",
    "######\n",
    "######\n",
    "# # Define the measure type you want to drop (e.g., \"MAE\", \"RMSE\")\n",
    "# measure_to_drop = \"MAE\"  # Change this value to drop a different measure type\n",
    "def drop_specific_rows(dataframes_no_na, dataframes_clean_data, measure_to_drop):\n",
    "    # Iterate through each DataFrame in the dataframes_no_na dictionary\n",
    "    for key, df in dataframes_no_na.items():\n",
    "        # Drop rows that contain the measure_to_drop in their names\n",
    "        df_clean = df[~df.iloc[:, 0].str.contains(measure_to_drop, na=False)]\n",
    "        \n",
    "        # Remove the \"_no_na\" suffix from the key and replace it with \"_clean\"\n",
    "        new_key = key.replace('_no_na', '_clean')\n",
    "        \n",
    "        # Save the cleaned DataFrame into the new dictionary\n",
    "        dataframes_clean_data[new_key] = df_clean\n",
    "\n",
    "    return dataframes_clean_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cleaning_for_unique_imputers(dataframes_clean_data):\n",
    "    # Iterate through each DataFrame in the dataframes_clean_data dictionary\n",
    "    for key, df in dataframes_clean_data.items():\n",
    "        # Create a dictionary to keep track of unique columns by imputer name\n",
    "        unique_imputers = {}\n",
    "        \n",
    "        # Iterate through each column in the DataFrame\n",
    "        for col in df.columns:\n",
    "            # Extract the imputer part from the column name using a split\n",
    "            if \"measure_and_missing_rates\" in col:\n",
    "                imputer_name=\"measure_and_missing_rates\"\n",
    "                unique_imputers[imputer_name] = col  # Store the original column name as value\n",
    "            elif \"Imputer(\" in col:\n",
    "                imputer_name = col.split(\"Imputer(\")[1].split(\")_Estim\")[0]  # Extract text between \"Imputer(\" and \")_Estim\"\n",
    "                \n",
    "                # If this imputer name has not been added to unique_imputers, add it\n",
    "                if imputer_name not in unique_imputers:\n",
    "                    unique_imputers[imputer_name] = col  # Store the original column name as value\n",
    "\n",
    "        # Create a list of columns to keep (unique imputers only)\n",
    "        columns_to_keep = list(unique_imputers.values())\n",
    "\n",
    "        # Filter the DataFrame to keep only the columns with unique imputer names\n",
    "        df_cleaned = df[columns_to_keep]\n",
    "        \n",
    "        # Update the DataFrame in the dictionary with the cleaned version\n",
    "        dataframes_clean_data[key] = df_cleaned\n",
    "    return dataframes_clean_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_column_names(dataframes_clean_data):\n",
    "    # Iterate through each DataFrame in the dataframes_clean_data dictionary\n",
    "    for key, df in dataframes_clean_data.items():\n",
    "        # Create a dictionary to map old column names to new column names (imputer names)\n",
    "        new_column_names = {}\n",
    "        \n",
    "        # Iterate through each column in the DataFrame\n",
    "        for col in df.columns:\n",
    "            # Extract the imputer part from the column name using a split\n",
    "\n",
    "            if \"Imputer(\" in col:\n",
    "                imputer_name = col.split(\"Imputer(\")[1].split(\")_Estim\")[0]  # Extract text between \"Imputer(\" and \")_Estim\"\n",
    "                # Map the old column name to the new imputer name\n",
    "                new_column_names[col] = imputer_name\n",
    "        \n",
    "        # Rename the columns in the DataFrame\n",
    "        df.rename(columns=new_column_names, inplace=True)\n",
    "        \n",
    "        # Update the DataFrame in the dictionary with the renamed columns\n",
    "        dataframes_clean_data[key] = df\n",
    "    return dataframes_clean_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_for_baseline(dataframes_clean_data):\n",
    "    # Drop specific columns from the \"baseline_clean\" dataframe\n",
    "    dataframes_clean_data[\"baseline_clean\"] = dataframes_clean_data[\"baseline_clean\"].drop(columns=[\"KNN-Imputer\", \"RF-Imputer\"])\n",
    "    return dataframes_clean_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def complete_statistics_plots(dataset_name,imputation_directory, dataframes_clean_data,missing_mechanism,y_axis_label,stats_directory_name):\n",
    "    # Initialize dictionaries to store data split by missing rates\n",
    "    data_by_missingrates = {}\n",
    "    baseline_data_by_missingness = {}\n",
    "\n",
    "    # Define the directory to save the stats and graphs\n",
    "    output_directory = os.path.join(imputation_directory, stats_directory_name)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Function to extract missing rate from the \"measure_and_missing_rates\" column\n",
    "    def extract_missing_rate(measure_string):\n",
    "        return measure_string.split('_')[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Iterate through each DataFrame in dataframes_clean_data\n",
    "    for key, df in dataframes_clean_data.items():\n",
    "        # Check if it is the baseline dataframe\n",
    "        if \"baseline_clean\" in key:\n",
    "            # Split baseline data by missing rate\n",
    "            for missing_rate in df['measure_and_missing_rates'].apply(extract_missing_rate).unique():\n",
    "                baseline_data_by_missingness[str(missing_rate)] = df[df['measure_and_missing_rates'].str.contains(f'_{missing_rate}')]\n",
    "        else:\n",
    "            # Initialize a dictionary for each feature selection dataframe\n",
    "            data_by_missingrates[key] = {}\n",
    "            # Split feature selection data by missing rate\n",
    "            for missing_rate in df['measure_and_missing_rates'].apply(extract_missing_rate).unique():\n",
    "                data_by_missingrates[key][str(missing_rate)] = df[df['measure_and_missing_rates'].str.contains(f'_{missing_rate}')]\n",
    "\n",
    "    # Calculate descriptive statistics and save to CSV files\n",
    "    for key, rates_data in data_by_missingrates.items():\n",
    "        for missing_rate, rate_df in rates_data.items():\n",
    "            # Calculate descriptive statistics\n",
    "            stats = rate_df.describe()\n",
    "            # Save to CSV\n",
    "            stats.to_csv(os.path.join(output_directory, f'{key}_missing_rate_{missing_rate}_stats.csv'))\n",
    "\n",
    "    for missing_rate, rate_df in baseline_data_by_missingness.items():\n",
    "        # Calculate descriptive statistics for baseline\n",
    "        stats = rate_df.describe()\n",
    "        # Save to CSV\n",
    "        stats.to_csv(os.path.join(output_directory, f'baseline_clean_missing_rate_{missing_rate}_stats.csv'))\n",
    "\n",
    "    # Define line styles and markers for diversity\n",
    "    line_styles = ['-', '--', '-.', ':']\n",
    "    markers = ['o', 's', '^', 'D', 'x', '*']  # Different markers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Generate graphs for each feature selection dataframe\n",
    "    def plot_imputer_values_vs_missing_rates(feature_selection_key, graph_name, y_axis_label):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Extract the missing rates and convert them to float for sorting and plotting\n",
    "\n",
    "        missing_rates = sorted([float(rate) for rate in baseline_data_by_missingness.keys()])\n",
    "\n",
    "        # Plot baseline data (without feature selection)\n",
    "        for idx, imputer in enumerate(baseline_data_by_missingness[str(missing_rates[0])].columns[1:]):  # Skip 'measure_and_missing_rates'\n",
    "            baseline_values = [baseline_data_by_missingness[str(missing_rate)][imputer].mean() for missing_rate in missing_rates]\n",
    "            plt.plot(\n",
    "                missing_rates,\n",
    "                baseline_values,\n",
    "                marker=markers[idx % len(markers)],\n",
    "                # linestyle=line_styles[idx % len(line_styles)],\n",
    "                linestyle=line_styles[(idx + len(baseline_data_by_missingness)) % len(line_styles)],\n",
    "                label=f'{imputer} (no FS)'\n",
    "            )\n",
    "        \n",
    "        # Plot data for the given feature selection key\n",
    "        for idx, imputer in enumerate(data_by_missingrates[feature_selection_key][str(missing_rates[0])].columns[1:]):  # Skip 'measure_and_missing_rates'\n",
    "            imputer_values = [data_by_missingrates[feature_selection_key][str(missing_rate)][imputer].mean() for missing_rate in missing_rates]\n",
    "            plt.plot(\n",
    "                missing_rates,\n",
    "                imputer_values,\n",
    "                marker=markers[idx % len(markers)],\n",
    "                # linestyle=line_styles[(idx + len(baseline_data_by_missingness)) % len(line_styles)],\n",
    "                label=imputer\n",
    "            )\n",
    "        \n",
    "        # Set plot labels and title\n",
    "        plt.xlabel('Missing Rates')\n",
    "        plt.ylabel(y_axis_label)\n",
    "        plt.title(f'{graph_name} Imputer Values vs Missing Rates')\n",
    "        plt.xticks(missing_rates, [f'{int(rate*100)}%' for rate in missing_rates])\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save the plot to the output directory\n",
    "        plt.savefig(os.path.join(output_directory, f'{graph_name}_Imputer_Values_vs_Missing_Rates.png'))\n",
    "        plt.close()\n",
    "\n",
    "    # Example usage of the plot function for each feature selection dataframe\n",
    "    for key in data_by_missingrates.keys():\n",
    "        formatted_key = key.replace(\"_clean\", \"\").replace(\"_\", \" \")\n",
    "        # Capitalize each word for a title\n",
    "        title = formatted_key.title()\n",
    "\n",
    "        title = dataset_name+\" \"+title +\" FS \" +missing_mechanism\n",
    "        plot_imputer_values_vs_missing_rates(key, graph_name=title, y_axis_label=y_axis_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "directory_list=[\"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#26_Cleveland_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MAR\"]\n",
    "\n",
    "\n",
    "\n",
    "# directory_list=[\"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#26_Cleveland_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MAR\",\n",
    "#                 \"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#26_Cleveland_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MCAR\",\n",
    "#                 \"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#26_Cleveland_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MNAR\",\n",
    "#                 \"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#27_Diabetic_Retinopathy_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MAR\",\n",
    "#                 \"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#27_Diabetic_Retinopathy_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MCAR\",\n",
    "#                 \"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#27_Diabetic_Retinopathy_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MNAR\",\n",
    "#                 \"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#28_Wisconsin_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MAR\",\n",
    "#                 \"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#28_Wisconsin_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MCAR\",\n",
    "#                 \"/Users/dylandominguez/Library/CloudStorage/GoogleDrive-domy7912@gmail.com/My Drive/Grad School/Thesis/DylanDominguez-S24-F24-MastersThesis_Shared(Old -DATA ONLY))/Part 2 - Feature Selection Data/Exp#28_Wisconsin_9_10_24_imp_pred_eval_10_trials_base_fs_pipelines/MNAR\",\n",
    "#                 ]\n",
    "\n",
    "\n",
    "for dir in directory_list:\n",
    "    # Initialize the dictionary to store DataFrames\n",
    "    dataframes = {}\n",
    "    # Initialize a new dictionary to store DataFrames without NA values\n",
    "    dataframes_no_na = {}\n",
    "    # Define the measure type you want to drop (e.g., \"MAE\", \"RMSE\")\n",
    "    measure_to_drop = \"MAE\"  # Change this value to drop a different measure type\n",
    "    # Initialize a new dictionary to store DataFrames with specific rows removed\n",
    "    dataframes_clean_data = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # MISSING MECHANISM Experiment Directory\n",
    "    imputation_directory = dir\n",
    "    y_axis_label=\"RMSE\"\n",
    "    missing_mechanism=os.path.basename(imputation_directory)\n",
    "\n",
    "    #Since we are using the same directory per dataset, we want to look at different files, the two files are shown below\n",
    "    #imputation_eval_final_results or prediction_metrics_final_results\n",
    "    experiment_type_name=\"imputation_eval_final_results\"\n",
    "\n",
    "    #name of the directory where the stats will be saved\n",
    "    stats_directory_name=\"stats_imputation_level\"\n",
    "\n",
    "    # Extract the directory name before MAR or MCAR or MNAR\n",
    "    parent_directory = os.path.basename(os.path.dirname(imputation_directory))\n",
    "    dataset_name = parent_directory.split('_')[1]  # Assuming \"Cleveland\" is always the second part\n",
    "\n",
    "\n",
    "\n",
    "    dataframes=load_experiment_data(dataframes,imputation_directory,experiment_type_name)\n",
    "    dataframes_no_na=drop_na(dataframes, dataframes_no_na)\n",
    "    dataframes_clean_data=drop_specific_rows(dataframes_no_na, dataframes_clean_data, measure_to_drop)\n",
    "    dataframes_clean_data=cleaning_for_unique_imputers(dataframes_clean_data)\n",
    "\n",
    "    dataframes_clean_data=update_column_names(dataframes_clean_data)\n",
    "\n",
    "    # dataframes_clean_data=drop_columns_for_baseline(dataframes_clean_data)\n",
    "    complete_statistics_plots(dataset_name,imputation_directory, dataframes_clean_data,missing_mechanism,y_axis_label,stats_directory_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure_and_missing_rates</th>\n",
       "      <th>KNN-Imputer</th>\n",
       "      <th>Mean-Imputer</th>\n",
       "      <th>RF-Imputer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE_0.1</td>\n",
       "      <td>0.301408</td>\n",
       "      <td>0.338129</td>\n",
       "      <td>0.299207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RMSE_0.2</td>\n",
       "      <td>0.312554</td>\n",
       "      <td>0.325977</td>\n",
       "      <td>0.301294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RMSE_0.3</td>\n",
       "      <td>0.340422</td>\n",
       "      <td>0.341739</td>\n",
       "      <td>0.335544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RMSE_0.4</td>\n",
       "      <td>0.329613</td>\n",
       "      <td>0.318981</td>\n",
       "      <td>0.324104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RMSE_0.5</td>\n",
       "      <td>0.307780</td>\n",
       "      <td>0.306817</td>\n",
       "      <td>0.322630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RMSE_0.1</td>\n",
       "      <td>0.308116</td>\n",
       "      <td>0.303318</td>\n",
       "      <td>0.289671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RMSE_0.2</td>\n",
       "      <td>0.279850</td>\n",
       "      <td>0.293049</td>\n",
       "      <td>0.273059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RMSE_0.3</td>\n",
       "      <td>0.339849</td>\n",
       "      <td>0.342907</td>\n",
       "      <td>0.335443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RMSE_0.4</td>\n",
       "      <td>0.352865</td>\n",
       "      <td>0.353004</td>\n",
       "      <td>0.366219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RMSE_0.5</td>\n",
       "      <td>0.290558</td>\n",
       "      <td>0.299224</td>\n",
       "      <td>0.329875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measure_and_missing_rates  KNN-Imputer  Mean-Imputer  RF-Imputer\n",
       "0                   RMSE_0.1     0.301408      0.338129    0.299207\n",
       "4                   RMSE_0.2     0.312554      0.325977    0.301294\n",
       "8                   RMSE_0.3     0.340422      0.341739    0.335544\n",
       "12                  RMSE_0.4     0.329613      0.318981    0.324104\n",
       "16                  RMSE_0.5     0.307780      0.306817    0.322630\n",
       "20                  RMSE_0.1     0.308116      0.303318    0.289671\n",
       "24                  RMSE_0.2     0.279850      0.293049    0.273059\n",
       "28                  RMSE_0.3     0.339849      0.342907    0.335443\n",
       "32                  RMSE_0.4     0.352865      0.353004    0.366219\n",
       "36                  RMSE_0.5     0.290558      0.299224    0.329875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_clean_data[\"RFE_clean\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_experiments_TEST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
